{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "rxl5MDk5bRPm"
   },
   "outputs": [],
   "source": [
    "import skfuzzy.cluster as fuzz\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Importar o conjunto de dados\n",
    "url1 = \"https://archive.ics.uci.edu/ml/machine-learning-databases/image/segmentation.data\"\n",
    "url2 = \"https://archive.ics.uci.edu/ml/machine-learning-databases/image/segmentation.test\"\n",
    "\n",
    "cols = [\"CLASS\", \"REGION-CENTROID-COL\", \"REGION-CENTROID-ROW\", \"REGION-PIXEL-COUNT\", \"SHORT-LINE-DENSITY-5\", \"SHORT-LINE-DENSITY-2\", \"VEDGE-MEAN\", \"VEDGE-SD\", \"HEDGE-MEAN\", \"HEDGE-SD\", \"INTENSITY-MEAN\",\"RAWRED-MEAN\",\"RAWBLUE-MEAN\",\"RAWGREEN-MEAN\",\"EXRED-MEAN\",\"EXBLUE-MEAN\",\"EXGREEN-MEAN\",\"VALUE-MEAN\",\"SATURATION-MEAN\",\"HUE-MEAN\"]\n",
    "\n",
    "df1 = pd.read_csv(url1, header=2, names=cols)\n",
    "df2 = pd.read_csv(url2, header=2, names=cols)\n",
    "df3 = pd.concat([df1, df2]).drop([\"REGION-CENTROID-COL\", \"REGION-CENTROID-ROW\", \"REGION-PIXEL-COUNT\"], axis=1)\n",
    "best_Us = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "it_ebJJ0bTrW"
   },
   "outputs": [],
   "source": [
    "df1 = df3.iloc[:,4:9] \n",
    "df2 = df3.iloc[:,10:19]\n",
    "df3 = df3.iloc[:,4:19]\n",
    "\n",
    "dfs = [df1,df2,df3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "FxnP1ROIcQJJ"
   },
   "outputs": [],
   "source": [
    "X = df3.iloc[:, :-1].to_numpy(dtype=np.float32)\n",
    "y = df3.iloc[:, -1].to_numpy()\n",
    "X = (X - X.mean(axis=0)) / X.std(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8r5LDS9RREz2",
    "outputId": "f048d935-f410-4072-b2de-bd9c52aaf81d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Melhor resultado de acordo com a Função objetivo: 13259.407415797887\n"
     ]
    }
   ],
   "source": [
    "#Para m=2\n",
    "n_clusters = 7\n",
    "\n",
    "for dfs in range(3): #Aqui selecionamos os 3 datasets\n",
    "    best_obj_func = np.inf # Executando o algoritmo FCM com a distância city-block personalizada\n",
    "    best_U = None # Melhor resultado\n",
    "    for i in range(50):\n",
    "        cntr, u, u0, d, jm, p, fpc = fuzz.cmeans(data=X.T, c=n_clusters, m=2, error=1e-3, maxiter=100, metric='cityblock')\n",
    "        if jm.mean() < best_obj_func:\n",
    "            best_obj_func = jm.mean()\n",
    "            best_U = u\n",
    "    best_Us.append(best_U) #best_Us contém todas as melhores matrizes de partição fuzzy obtidas no algoritmo FCM\n",
    "\n",
    "best_jm = np.inf\n",
    "\n",
    "cntr, u, _, _, jm, _, _ = fuzz.cmeans(data=X.T, c=n_clusters, m=2, error=1e-3, maxiter=1000, metric='cityblock')\n",
    "if jm.mean() < best_jm:\n",
    "    best_jm = jm.mean()\n",
    "    best_U = u\n",
    "print(\"Melhor resultado de acordo com a Função objetivo:\", best_jm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TxIMKw-xRjzi",
    "outputId": "896f8f18-ea59-4efb-a16e-2a4e9cfbe06d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Melhor resultado de acordo com a Função objetivo: 22652.776315691364\n"
     ]
    }
   ],
   "source": [
    "#Para m = 1.6\n",
    "best_jm = np.inf\n",
    "cntr, u, _, _, jm, _, _ = fuzz.cmeans(data=X.T, c=n_clusters, m=1.6, error=1e-3, maxiter=100, metric='cityblock')\n",
    "if jm.mean() < best_jm:\n",
    "    best_jm = jm.mean()\n",
    "    best_U = u\n",
    "print(\"Melhor resultado de acordo com a Função objetivo:\", best_jm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mKHvPLoad6lj",
    "outputId": "aa721dea-a24d-4645-d009-5af67d7c92cd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Melhor resultado de acordo com a Função objetivo: 36214.64616619606\n"
     ]
    }
   ],
   "source": [
    "#Para m = 1.1\n",
    "best_jm = np.inf\n",
    "cntr, u, _, _, jm, _, _ = fuzz.cmeans(data=X.T, c=n_clusters, m=1.1, error=1e-3, maxiter=100, metric='cityblock')\n",
    "if jm.mean() < best_jm:\n",
    "    best_jm = jm.mean()\n",
    "    best_U = u\n",
    "print(\"Melhor resultado de acordo com a Função objetivo:\", best_jm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xSzgS-qIabst",
    "outputId": "84944be8-ec62-4f47-df47-fe9be2536c2a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modified Partition Coefficient (df1): 611.7195100397478 Partition entropy (df1): 1.4762017904762232 \n",
      "Modified Partition Coefficient (df2): 859.0225233306347 Partition entropy (df2): 1.8994142429450755 \n",
      "Modified Partition Coefficient (df3): 1092.5981212658444 Partition entropy (df3): 1.8724476749105976 \n"
     ]
    }
   ],
   "source": [
    "#MODIFIED PARTITION COEFFICIENT\n",
    "\n",
    "#Para df1\n",
    "cntr, u, u0, d, jm, p, fpc = fuzz.cmeans(data=df1.T, c=n_clusters, m=2, error=1e-3, maxiter=100, metric='cityblock')\n",
    "FE = -np.sum(u*np.log(u))\n",
    "PE = -np.sum(u.mean(axis=1)*np.log(u.mean(axis=1)))\n",
    "PC = (FE - PE) / np.log(n_clusters)\n",
    "print(f\"Modified Partition Coefficient (df1): {PC} Partition entropy (df1): {PE} \")\n",
    "\n",
    "#Para df2\n",
    "cntr, u, _, _, _, _, _ = fuzz.cmeans(data=df2.T, c=n_clusters, m=2, error=1e-3, maxiter=100, metric='cityblock')\n",
    "FE = -np.sum(u*np.log(u))\n",
    "PE = -np.sum(u.mean(axis=1)*np.log(u.mean(axis=1)))\n",
    "PC = (FE - PE) / np.log(n_clusters)\n",
    "print(f\"Modified Partition Coefficient (df2): {PC} Partition entropy (df2): {PE} \")\n",
    "\n",
    "#Para df3\n",
    "cntr, u, u0, d, jm, p, fpc = fuzz.cmeans(data=X.T, c=n_clusters, m=2, error=1e-3, maxiter=100, metric='cityblock')\n",
    "FE = -np.sum(u*np.log(u))\n",
    "PE = -np.sum(u.mean(axis=1)*np.log(u.mean(axis=1)))\n",
    "PC = (FE - PE) / np.log(n_clusters)\n",
    "print(f\"Modified Partition Coefficient (df3): {PC} Partition entropy (df3): {PE} \")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Fgigc-vcjcTl",
    "outputId": "a8172c2a-29ed-455d-d1ce-f21ca5e704d9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Partição nítida do conjunto de dados 1:\n",
      "[3 3 3 ... 3 3 3]\n",
      "Partição nítida do conjunto de dados 2:\n",
      "[1 1 1 ... 1 1 1]\n",
      "Partição nítida do conjunto de dados 3:\n",
      "[5 5 5 ... 5 5 3]\n"
     ]
    }
   ],
   "source": [
    "# Definir o número de clusters\n",
    "n_clusters = 7\n",
    "\n",
    "# Fuzzy c-means para cada dataset\n",
    "cntr1, u1, _, _, _, _, _ = fuzz.cmeans(data=df1.T, c=n_clusters, m=2, error=1e-3, maxiter=100, metric='cityblock')\n",
    "cntr2, u2, _, _, _, _, _ = fuzz.cmeans(data=df2.T, c=n_clusters, m=2, error=1e-3, maxiter=100, metric='cityblock')\n",
    "cntr3, u3, _, _, _, _, _ = fuzz.cmeans(data=X.T, c=n_clusters, m=2, error=1e-3, maxiter=100, metric='cityblock')\n",
    "\n",
    "# Obter as partições nítidas\n",
    "u1_crisp = np.argmax(u1, axis=0)\n",
    "u2_crisp = np.argmax(u2, axis=0)\n",
    "u3_crisp = np.argmax(u3, axis=0)\n",
    "\n",
    "# Imprimir os resultados das partições CRISP\n",
    "print(\"Partição nítida do conjunto de dados 1:\")\n",
    "print(u1_crisp)\n",
    "print(\"Partição nítida do conjunto de dados 2:\")\n",
    "print(u2_crisp)\n",
    "print(\"Partição nítida do conjunto de dados 3:\")\n",
    "print(u3_crisp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 236
    },
    "id": "96IFSM3ekX9D",
    "outputId": "d095dad4-ca97-4c77-9601-3c160a5a0130"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusted Rand Index for dataset 1: 0.02931265244977159\n",
      "Adjusted Rand Index for dataset 2: 0.01437980247916568\n",
      "Adjusted Rand Index for dataset 3: 0.014155398710015086\n"
     ]
    }
   ],
   "source": [
    "# ÍNDICE DE RAND AJUSTADO\n",
    "# Converter partição fuzzy para crisp\n",
    "from sklearn.metrics import adjusted_rand_score\n",
    "\n",
    "labels1 = np.argmax(u1, axis=0)\n",
    "labels2 = np.argmax(u2, axis=0)\n",
    "labels3 = np.argmax(u3, axis=0)\n",
    "\n",
    "y1 = df1.iloc[:, -1].to_numpy()\n",
    "y2 = df2.iloc[:, -1].to_numpy()\n",
    "y3 = df3.iloc[:, -1].to_numpy()\n",
    "\n",
    "\n",
    "ari1 = adjusted_rand_score(y1, labels1)\n",
    "ari2 = adjusted_rand_score(y2, labels2)\n",
    "ari3 = adjusted_rand_score(y3, labels3)\n",
    "\n",
    "# Print results\n",
    "print(\"Adjusted Rand Index for dataset 1:\", ari1)\n",
    "print(\"Adjusted Rand Index for dataset 2:\", ari2)\n",
    "print(\"Adjusted Rand Index for dataset 3:\", ari3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "JsaQ_JTYshXp"
   },
   "outputs": [],
   "source": [
    "labels = np.argmax(u, axis=0)\n",
    "true_labels = np.array([int(i)-1 for i in y]) # Convert y to 0-based labels\n",
    "# Compute confusion matrix\n",
    "cm = confusion_matrix(true_labels, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.22649005798115063"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def fmeasure(cm):\n",
    "    l = len(cm)\n",
    "    s = cm.sum()\n",
    "    s_true = cm.sum(axis = 1)\n",
    "    s_predict = cm.sum(axis = 0)\n",
    "    f_score = np.zeros((l, l))\n",
    "    for i in range(dfs):\n",
    "        for j in range(7):\n",
    "            f_score[i, j] = (2*cm[i, j])/(s_true[i]+s_predict[j])\n",
    "\n",
    "    return ((f_score.max(axis =1)*s_true).sum())/s\n",
    "\n",
    "fmeasure(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Índice de Rand entre partições 1 e 2: 0.995\n",
      "F-measure entre partições 1 e 2: 0.233\n",
      "Índice de Rand entre partições 1 e 3: 1.000\n",
      "F-measure entre partições 1 e 3: 0.000\n",
      "Índice de Rand entre partições 1 e 4: 1.000\n",
      "F-measure entre partições 1 e 4: 0.000\n",
      "Índice de Rand entre partições 1 e 5: 0.925\n",
      "F-measure entre partições 1 e 5: 0.244\n",
      "Índice de Rand entre partições 1 e 6: 0.995\n",
      "F-measure entre partições 1 e 6: 0.002\n",
      "Índice de Rand entre partições 1 e 7: 1.000\n",
      "F-measure entre partições 1 e 7: 0.185\n",
      "Índice de Rand entre partições 2 e 3: 0.995\n",
      "F-measure entre partições 2 e 3: 0.322\n",
      "Índice de Rand entre partições 2 e 4: 0.995\n",
      "F-measure entre partições 2 e 4: 0.144\n",
      "Índice de Rand entre partições 2 e 5: 0.929\n",
      "F-measure entre partições 2 e 5: 0.438\n",
      "Índice de Rand entre partições 2 e 6: 1.000\n",
      "F-measure entre partições 2 e 6: 0.000\n",
      "Índice de Rand entre partições 2 e 7: 0.995\n",
      "F-measure entre partições 2 e 7: 0.000\n",
      "Índice de Rand entre partições 3 e 4: 1.000\n",
      "F-measure entre partições 3 e 4: 0.332\n",
      "Índice de Rand entre partições 3 e 5: 0.925\n",
      "F-measure entre partições 3 e 5: 0.005\n",
      "Índice de Rand entre partições 3 e 6: 0.995\n",
      "F-measure entre partições 3 e 6: 0.280\n",
      "Índice de Rand entre partições 3 e 7: 1.000\n",
      "F-measure entre partições 3 e 7: 0.042\n",
      "Índice de Rand entre partições 4 e 5: 0.925\n",
      "F-measure entre partições 4 e 5: 0.009\n",
      "Índice de Rand entre partições 4 e 6: 0.995\n",
      "F-measure entre partições 4 e 6: 0.005\n",
      "Índice de Rand entre partições 4 e 7: 1.000\n",
      "F-measure entre partições 4 e 7: 0.000\n",
      "Índice de Rand entre partições 5 e 6: 0.929\n",
      "F-measure entre partições 5 e 6: 0.523\n",
      "Índice de Rand entre partições 5 e 7: 0.925\n",
      "F-measure entre partições 5 e 7: 0.143\n",
      "Índice de Rand entre partições 6 e 7: 0.995\n",
      "F-measure entre partições 6 e 7: 0.185\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics.cluster import adjusted_rand_score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "\n",
    "# Generate 7 random partitions using KMeans\n",
    "n_clusters = 7\n",
    "partitions = []\n",
    "for i in range(n_clusters):\n",
    "    kmeans = KMeans(n_clusters=n_clusters, random_state=i)\n",
    "    labels = kmeans.fit_predict(X)\n",
    "    partitions.append(labels)\n",
    "\n",
    "# Compute ARI and F-measure for all pairs of partitions\n",
    "for i in range(n_clusters):\n",
    "    for j in range(i+1, n_clusters):\n",
    "        ari = adjusted_rand_score(partitions[i], partitions[j])\n",
    "        fmeasure = f1_score(partitions[i], partitions[j], average='weighted')\n",
    "        print(f\"Índice de Rand entre partições {i+1} e {j+1}: {ari:.3f}\")\n",
    "        print(f\"F-measure entre partições {i+1} e {j+1}: {fmeasure:.3f}\")\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
